{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Clicks Review\n",
    "\n",
    "The web has become a significant part of our life. Most of our time has spent on using search engines to navigate through the internet. Since search engines are free to use, they are using advertisement as a business strategy. How that works is that whenever a user searches a query, search engine shows some ads and organic search results. If the user clicks an ad link, the search engine will get money from the advertiser. Since the number of user search is finite, in order not to waste those opportunities, search engines should return most relevant advertisement to the user. If an advertisement has shown many times, it is easier to predict the click-through rate (CTR) of an ad. However, the problem occurs when there is a new advertisement. Since we have not observed any user interaction with that advertisement, it is hard to predict the CTR of that ad. In this paper, authors tackle this problem. Their solution is to use the length of the ad and the words in the ad, to gain more information about the CTR.\n",
    "\n",
    "Click-through rate (CTR) is the ratio of the number of clicks to the number of impressions.  For instance, if an advertisement is shown 20 times and it got clicked 4 times CTR would be 0.2. In order to know if the search engine prediction model is working as expected, predicted CTR of the model and actual CTR can be compared. \n",
    "\n",
    "It seems that the most effective factor is the place of the add. If it is shown in the first place, CTR will increase. However, sorting the ads place wrongly would dissatisfy advertisers and users. It also the hurts the revenue of the search engine.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "Authors used logistic regression to predict CTR of an ad. The logistic training method was limited-memory Broyden-Fletcher-Goldfarb-Shanno (L-BFGS). Instead of starting with random initial weights, they used zero-mean Gaussian weight priors. In order to eliminate outliers, they removed data points has features that are five standard deviations away from the mean. Authors also used boosted regression trees. However, they have not noticed any performance improvement over the logistic regression. That's why they prefer to continue with logistic regression which is a lot simpler than boosted regression trees. \n",
    "\n",
    "## Term CTR and related term CTR\n",
    "\n",
    "For the first set of features, they used term CTR and related term CTR. Term CTR is very intuitive; it is approximately the average CTR of a term.\n",
    "\n",
    "Term CTR:\n",
    "\\begin{align}\n",
    "CTR(t) = \\frac{\\alpha * \\overline{CTR} + N * CTR(ad_{term})}{\\alpha + N}\n",
    "\\end{align}\n",
    "\n",
    "where $\\overline{CTR}$ is the average CTR of all ads, $\\alpha$ is the smoothing value of the prior, N is the number of ads that has the term, and $CTR(ad_{term}$ is the average CTR for the ads containing that term.\n",
    "\n",
    "However, related term CTR is a little bit complex. It is dependent on a function $R_{mn}(t)$ where t is the similar terms, m is the removed number of words in similar terms and n is the removed number of words from ad terms. This function is:\n",
    "\n",
    "\\begin{align}\n",
    "R_{mn}(t) = \n",
    "\\begin{cases}\n",
    "         \\hspace{13mm}     |ad_{term} \\cap t|>0 \\text{ and}\\\\\n",
    "              ad \\colon  \\hspace{7mm}  |t - ad_{term}| = m \\text{ and}\\\\\n",
    "         \\hspace{13mm}     |ad_{term} - t| = n \n",
    "\\end{cases}\n",
    "\\end{align}\n",
    " In order to calculate related term CTR we use this equation:\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "CTR_{mn}(term) = \\frac{1}{|R_{mn}(term)|} \\sum_{x \\epsilon R_{mn}(term)} CTR_x\n",
    "\\end{align}\n",
    "\n",
    "This is simply the average of related terms CTR. This feature decreased the error rate by 6%.\n",
    "\n",
    "## Ad Quality as a Feature\n",
    "\n",
    "Estimating CTR by only its terms does not give accurate results because the variance of a term CTR is huge for some words. That's why they also need to know the quality of the ad.\n",
    "They use appearance, attention capture, reputation, landing page quality and relevance for the feature set. From these five feature set, they build 81 features. This step decreases the error rate by 1%. Also adding some significant words in ads title as a feature reduces the error rate by 4%. \n",
    "\n",
    "## Specificity as a Feature\n",
    "\n",
    "Also, if the advertisement is targetted on a particular category with different keywords, it's CTR is the sum of all keywords since the title is the same for all keywords. However, if the title is dynamic with the keywords, then the CTR of an ad would be the CTR of its keyword. Since in the first case we sum all CTRs of keywords and in the second case, we get only keyword's CTR. This would create some problems since it would increase the variance for the same keywords. So they had to know how specific or broad a category of an ad. To do that they use Naive Bayes classifier, and 74 categories as target variables. If the entropy of category probabilities are high it means that ad category is more general, if entropy is low ad is about a specific category. When this entropy value used as a feature it decreased the error rate by another 5%.\n",
    "\n",
    "## Frequency of terms in ad as a Feature\n",
    "\n",
    "Another feature is how common an ad terms are. It is comprised of two features, and the first one is how many search result pages a search engine return and the second one is how commonly the search queries contain ad words. However, this features did not increase the accuracy of the model. Authors claim that previous features provide information about these two features, that's why it did not increase the accuracy.\n",
    "\n",
    "## Discussion\n",
    "\n",
    "Since logistic regression would give weights for each feature. We can correlate weights of a feature with the importance of a feature. Interesting ones in the top ten features are the $log(\\text{#chars in term})$ and $log(\\text{category entropy}).  The more character in the ads, the more clicks it gets.\n",
    "\n",
    "With the model, they predict that CTR would converge to some number but after how many impressions it would converge to that number is another problem. It is safe to say that real CTR would be very close to the predicted CTR  after 100 impressions. \n",
    "\n",
    "Overall the paper is well designed and easy to read. Especially, I have found using entropy of category probabilities to find ads specify both intuitive and smart. However emphasis only on feature selection rather than other best practices(regularization, dimensionality reduction, etc.) is a little bit problematic, but I understand that it is for solving the initial problem of predicting CTR of a new advertisement. Also, highlighting the percentage (30%) of the decrease in error rate may be misleading because if the initial error rate was 5%, decreasing it to 3.5% would mean 30% reduction of error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
